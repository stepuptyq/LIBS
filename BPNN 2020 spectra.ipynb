{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0,c0 = 40, 100\n",
      "batch_size = 1\n",
      "k = 30468\n",
      "error = [7.21241122e-09]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 277197\n",
      "error = [-3.1658505e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 68371\n",
      "error = [-2.64819495e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 552121\n",
      "error = [4.07499524e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 273144\n",
      "error = [-3.97062496e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 91220\n",
      "error = [-2.67204119e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 87547\n",
      "error = [-1.34230449e-09]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 152277\n",
      "error = [-1.62082752e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 86637\n",
      "error = [9.45431822e-09]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 301765\n",
      "error = [-1.69359068e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 74317\n",
      "error = [1.50012821e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 315944\n",
      "error = [3.04537299e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 42960\n",
      "error = [-2.84333446e-10]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 105817\n",
      "error = [2.11925968e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 163839\n",
      "error = [9.05730158e-10]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 355884\n",
      "error = [-5.78081549e-09]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 174963\n",
      "error = [-7.45514206e-09]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 109242\n",
      "error = [-3.11574766e-10]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 74775\n",
      "error = [-7.84780285e-09]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 178396\n",
      "error = [-2.29997816e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 49047\n",
      "error = [4.80587117e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 256965\n",
      "error = [1.90577172e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 222062\n",
      "error = [3.90602795e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 289430\n",
      "error = [6.07913808e-09]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 350970\n",
      "error = [2.77601764e-09]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 188513\n",
      "error = [1.40458052e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 278727\n",
      "error = [-1.47773693e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 114077\n",
      "error = [1.61096436e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 155058\n",
      "error = [4.05766976e-10]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 330166\n",
      "error = [1.71289207e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 94324\n",
      "error = [4.93493404e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 135423\n",
      "error = [-3.68653119e-09]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 99230\n",
      "error = [2.85305854e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 67260\n",
      "error = [3.65950188e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 4903\n",
      "error = [3.53963127e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 85630\n",
      "error = [4.53426092e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 226610\n",
      "error = [3.4321546e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 170473\n",
      "error = [3.7998899e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 125928\n",
      "error = [-5.90587668e-09]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 216943\n",
      "error = [4.67854622e-09]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 411498\n",
      "error = [-1.00312092e-09]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 330671\n",
      "error = [2.49490637e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 359460\n",
      "error = [2.9512969e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 171463\n",
      "error = [-7.89382426e-09]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 23896\n",
      "error = [-3.55011157e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 88331\n",
      "error = [-2.49761137e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 549642\n",
      "error = [3.57073257e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 322595\n",
      "error = [3.57779558e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 100855\n",
      "error = [-4.68630241e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 172233\n",
      "error = [-1.65599058e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 117414\n",
      "error = [1.08708533e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 221846\n",
      "error = [-2.36842457e-09]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 175798\n",
      "error = [2.07609803e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 160798\n",
      "error = [8.64062866e-09]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 146595\n",
      "error = [2.13129237e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 50252\n",
      "error = [3.31863124e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 291403\n",
      "error = [-2.69459428e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 91341\n",
      "error = [2.21474128e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 353571\n",
      "error = [-7.87318022e-09]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "batch_size = 1\n",
      "k = 161542\n",
      "error = [-1.91907458e-08]\n",
      "indexi = 0\n",
      "indexi = 1\n",
      "done in 490.512s\n",
      "predict_val = [14.97924351 11.06289699  6.97110807 13.66197814  0.8530451 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title = ['REC', 'RET', 'REP', 'RSD', 'LOD', 'R2']\n",
      "value = [2.4164244171450484, 2.4187054671587602, 0.30911215368624845, nan, 0.16668426208019063, 0.9998513135583544]\n",
      "cal_true = ['cal_true', 15.002104209397503, 11.035779821758295, 6.85, 13.720773625069198, 0.8436255066526641]\n",
      "cmp0 = [['cal_true', 15.002104209397503, 11.035779821758295, 6.85, 13.720773625069198, 0.8436255066526641], ['cal_predict', 14.979243507916728, 11.062896993315537, 6.971108068210234, 13.661978140425637, 0.8530450951910292], ['cal_stander_derivation', 0.003919644882981051, 0.050513371119116815, 0.09617832198700894, 0.09830740421985211, 0.027348167644064298]]\n",
      "cmp0 = [['cal_true', 15.002104209397503, 11.035779821758295, 6.85, 13.720773625069198, 0.8436255066526641], ['cal_predict', 14.979243507916728, 11.062896993315537, 6.971108068210234, 13.661978140425637, 0.8530450951910292], ['cal_stander_derivation', 0.003919644882981051, 0.050513371119116815, 0.09617832198700894, 0.09830740421985211, 0.027348167644064298]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yongq\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:88: RuntimeWarning: divide by zero encountered in true_divide\n",
      "C:\\Users\\yongq\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:117: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "# coding: utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import os\n",
    "import random\n",
    "import xlrd\n",
    "import xlwt\n",
    "import sys\n",
    "from scipy import optimize\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, mutual_info_classif\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn import manifold\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "########################################################################################################################\n",
    "# 线性拟合\n",
    "def f_1(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "########################################################################################################################\n",
    "# 除去重复\n",
    "def remove_duplicate(x):  # the input should be the list style\n",
    "    x = x.reshape(1, -1)\n",
    "    x = x[0, :].tolist()\n",
    "    output = []\n",
    "    for i in x:\n",
    "        if i not in output:\n",
    "            output.append(i)\n",
    "    return output\n",
    "\n",
    "########################################################################################################################\n",
    "# 归一化同种样品的能量\n",
    "def normalize_single(spectra):\n",
    "    spectra_max = np.max(spectra, axis=1)\n",
    "    spectra_max = spectra_max.reshape(-1, 1)\n",
    "    spectra_mean = np.mean(spectra)\n",
    "    spectra_output = spectra*spectra_mean/spectra_max\n",
    "    return spectra_output\n",
    "\n",
    "########################################################################################################################\n",
    "# 归一化同种样品的能量\n",
    "def normalize_single_1(spectra):\n",
    "    wh = np.where(spectra == np.max(spectra))\n",
    "    spectra_max = spectra[:, wh[1][0]]\n",
    "    spectra_max = spectra_max.reshape(-1, 1)\n",
    "    spectra_mean = np.mean(spectra_max)\n",
    "    spectra_output = spectra * spectra_mean / spectra_max\n",
    "    return spectra_output\n",
    "\n",
    "########################################################################################################################\n",
    "# 归一化同种样品的能量\n",
    "def normalize_single_2(spectra):\n",
    "    spectra_mean_single = np.mean(spectra, axis=1)\n",
    "    spectra_mean_single = spectra_mean_single.reshape(-1, 1)\n",
    "    spectra_mean = np.mean(spectra)\n",
    "    spectra_output = spectra * spectra_mean / spectra_mean_single\n",
    "    return spectra_output\n",
    "\n",
    "########################################################################################################################\n",
    "# 归一化样品的能量\n",
    "def normalize(spectra, group_set):\n",
    "    X_output = np.zeros((spectra.shape[0], spectra.shape[1]))\n",
    "    temp = remove_duplicate(group_set)\n",
    "    group_set = group_set[:, 0].tolist()\n",
    "    for indexj in range(len(temp)):\n",
    "        temp_order = [i for i, x in enumerate(group_set) if x == temp[indexj]]\n",
    "        X_temp = spectra[temp_order, :]\n",
    "        X_temp = normalize_single_1(X_temp)\n",
    "        X_output[temp_order] = X_temp\n",
    "    return X_output\n",
    "\n",
    "########################################################################################################################\n",
    "# 归一化样品的能量\n",
    "def normalize1(spectra):\n",
    "    spectra_mean_single = np.mean(spectra, axis=1)\n",
    "    spectra_mean_single = spectra_mean_single.reshape(-1, 1)\n",
    "    spectra_mean = np.mean(spectra)\n",
    "    X_output = spectra * spectra_mean / spectra_mean_single\n",
    "    return X_output\n",
    "\n",
    "########################################################################################################################\n",
    "# 相对标准差\n",
    "def relative_standard_derivation(x_predict, x_te):  # the imput should be the list style\n",
    "    output = np.std((x_predict - x_te) / x_te) #* np.sqrt(len(x_te) / (len(x_te) - 1))\n",
    "    return output\n",
    "\n",
    "########################################################################################################################\n",
    "# 相对偏差\n",
    "def relative_error(x_predict, x_true):  # the imput should be the list style\n",
    "    output = np.mean(abs(x_predict - x_true) / x_true)\n",
    "    return output\n",
    "\n",
    "########################################################################################################################\n",
    "# limited of detection\n",
    "def limited_of_detection(slope, rsd_calibration):\n",
    "    output = 3 * np.mean(rsd_calibration) / slope\n",
    "    return output\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0.0)\n",
    "\n",
    "def relu_deriv(x):\n",
    "    x[x > 0] = 1.0\n",
    "    x[x <= 0] = 0.0\n",
    "    return x\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_deriv(x):\n",
    "    return 1.0 - np.tanh(x)*np.tanh(x)\n",
    "\n",
    "def logistic(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def logistic_derivative(x):\n",
    "    return logistic(x)*(1-logistic(x))\n",
    "\n",
    "def prelu(x):\n",
    "    return np.maximum(x, 0.0) + 0.25*np.minimum(x, 0.0)\n",
    "\n",
    "def prelu_deriv(x):\n",
    "    x[x > 0] = 1.0\n",
    "    x[x < 0] = 0.25\n",
    "    return x\n",
    "\n",
    "class BPNNet:\n",
    "\n",
    "    def __init__(self, layers, activation=[\"tanh\", \"tanh\"], batch_size=\"None\"):\n",
    "        self.layers = layers\n",
    "        # active function\n",
    "        self.activation = activation\n",
    "        if self.activation[0] == 'logistic':\n",
    "            self.activation0 = logistic\n",
    "            self.activation0_deriv = logistic_derivative\n",
    "        elif self.activation[0] == 'tanh':\n",
    "            self.activation0 = tanh\n",
    "            self.activation0_deriv = tanh_deriv\n",
    "        elif self.activation[0] == 'relu':\n",
    "            self.activation0 = relu\n",
    "            self.activation0_deriv = relu_deriv\n",
    "        elif self.activation[0] == 'prelu':\n",
    "            self.activation0 = prelu\n",
    "            self.activation0_deriv = prelu_deriv\n",
    "        if self.activation[1] == 'logistic':\n",
    "            self.activation1 = logistic\n",
    "            self.activation1_deriv = logistic_derivative\n",
    "        elif self.activation[1] == 'tanh':\n",
    "            self.activation1 = tanh\n",
    "            self.activation1_deriv = tanh_deriv\n",
    "        elif self.activation[1] == 'relu':\n",
    "            self.activation1 = relu\n",
    "            self.activation1_deriv = relu_deriv\n",
    "        elif self.activation[1] == 'prelu':\n",
    "            self.activation1 = prelu\n",
    "            self.activation1_deriv = prelu_deriv\n",
    "        # batch_size\n",
    "        if batch_size == \"None\":\n",
    "            self.batch_size = 0\n",
    "        else:\n",
    "            self.batch_size = batch_size\n",
    "        # random weights & weights updates\n",
    "        self.weights = []\n",
    "        self.weights.append((2*np.random.random((layers[0]+1,layers[1]))-1)*0.25)\n",
    "        for i in range(2,len(self.layers)):\n",
    "            self.weights.append((2*np.random.random((layers[i - 1],layers[i])) - 1) * 0.25)\n",
    "        # random weights & weights updates\n",
    "        self.updates = []\n",
    "        self.updates.append(np.zeros((self.layers[0] + 1, self.layers[1])))\n",
    "        for i in range(2,len(self.layers)):\n",
    "            self.updates.append(np.zeros((self.layers[i - 1], self.layers[i])))\n",
    "    def fit(self, X, y, learning_rate_max=0.3, learning_rate_min=0.1, epochs=2000000, error_threshold=1e-8):  # learning_rate=0.2\n",
    "        # self.weights 的数据更新\n",
    "        self.weights[0] = (2*np.random.random((self.layers[0]+1, self.layers[1]))-1)*0.25\n",
    "        for i in range(2, len(self.layers)):\n",
    "            self.weights[i - 1] = (2*np.random.random((self.layers[i - 1],self.layers[i])) - 1) * 0.25\n",
    "        #print(self.weights)\n",
    "        # atlest_2d函数:确认X至少二位的矩阵\n",
    "        X = np.atleast_2d(X)\n",
    "        # 初始化矩阵全是1（行数，列数+1是为了有B这个偏向）\n",
    "        temp = np.ones([X.shape[0], X.shape[1]+1])\n",
    "        # 行全选，第一列到倒数第二列\n",
    "        temp[:,0:-1]=X\n",
    "        X = temp\n",
    "        # 真实值的y数组\n",
    "        y = np.array(y)\n",
    "        # batch_size 的mini_batch计算\n",
    "        batch_size = int(self.batch_size * X.shape[0])+1\n",
    "        print('batch_size = '+str(batch_size))\n",
    "        # epoch 每一次循环的BP\n",
    "        for k in range(epochs):\n",
    "            learning_rate = learning_rate_max - (learning_rate_max-learning_rate_min) * k/epochs\n",
    "            # mini_batch 随机取出规定数目的序号list\n",
    "            order = random.sample(range(X.shape[0]), batch_size)\n",
    "            #print(order)\n",
    "            # self.updates 的数据更新\n",
    "            self.updates[0] = np.zeros((self.layers[0] + 1, self.layers[1]))\n",
    "            for i in range(2, len(self.layers)):\n",
    "                self.updates[i-1] = np.zeros((self.layers[i - 1], self.layers[i]))\n",
    "            # print(self.updates)\n",
    "            # mini_batch 梯度下降抽样\n",
    "            error = 0\n",
    "            error_cache = 1\n",
    "            for j in range(batch_size):\n",
    "                temp_j = order[j]\n",
    "                # 根据order产生的随机数数列，循环每次一个样本\n",
    "                a = [X[temp_j]]\n",
    "                a.append(self.activation0(np.dot(a[0], self.weights[0])))\n",
    "                a.append(self.activation1(np.dot(a[1], self.weights[1])))\n",
    "                # 向前传播，得到每个节点的输出结果\n",
    "                error_temp = y[temp_j] - a[-1]\n",
    "                error += error_temp\n",
    "            error = error/batch_size   # 最后一层错误率\n",
    "            deltas = [error * self.activation1_deriv(a[-1])]\n",
    "            deltas.append(deltas[-1].dot(self.weights[1].T) * self.activation0_deriv(a[1]))\n",
    "            deltas.reverse()\n",
    "            if abs(error) <= error_threshold:\n",
    "                print('k = '+str(k))\n",
    "                print('error = '+str(error))\n",
    "                break\n",
    "            elif k==epochs_whole-1:\n",
    "                self.weights = weights_cache\n",
    "                print('iteration steps out of band')\n",
    "                print('error = '+str(error_cache))\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                self.updates[i] += learning_rate * layer.T.dot(delta)\n",
    "            for i in range(len(self.updates)):\n",
    "                self.weights[i] += self.updates[i]/batch_size\n",
    "            if error < error_cache:\n",
    "                error_cache = error\n",
    "                weights_cache = self.weights\n",
    "    def predict(self, x):\n",
    "        # x=np.array(x)\n",
    "        r1, c1 = x.shape\n",
    "        aa = np.ones(shape=[r1, 1])\n",
    "        for indexi in range(r1):\n",
    "            temp = np.ones(c1 + 1)\n",
    "            temp[0:-1] = x[indexi].T\n",
    "            a = temp\n",
    "            a = self.activation0(np.dot(a, self.weights[0]))\n",
    "            a = self.activation1(np.dot(a, self.weights[1]))\n",
    "            aa[indexi] = a\n",
    "        return (aa)\n",
    "    def load_weights(self, path_load):\n",
    "        '''''\n",
    "        worksheet = xlrd.open_workbook(path_load)\n",
    "        sheet_names = worksheet.sheet_names()\n",
    "        '''''\n",
    "        for indexi in range(len(self.weights)):\n",
    "            data = pd.read_excel(path_load, sheet_name=str(indexi),\n",
    "                                 header=0, skiprows=0)\n",
    "            self.weights[indexi] = np.array(data)\n",
    "\n",
    "    def save_weights(self, path_save):\n",
    "        '''''\n",
    "        workbook = xlwt.Workbook(encoding='ascii')\n",
    "\n",
    "        for indexi in range(len(self.weights)):\n",
    "            cmp = self.weights[indexi]\n",
    "            worksheet = workbook.add_sheet(str(indexi))\n",
    "            for i in range(len(cmp)):\n",
    "                for j, k in enumerate(cmp[i]):\n",
    "                    worksheet.write(i, j, k)\n",
    "        workbook.save(path_save)\n",
    "        '''''\n",
    "        with pd.ExcelWriter(path_save) as writer:\n",
    "            for indexi in range(len(self.weights)):\n",
    "                print('indexi = '+str(indexi))\n",
    "                data = self.weights[indexi]\n",
    "                data = pd.DataFrame(data)\n",
    "                data.to_excel(writer, sheet_name=str(indexi), index=False, header=False)\n",
    "'''\n",
    "    def rigidity_normalization(y, range0=range(300,320), range1=range(400,420)):\n",
    "        peek0 = np.max(y[range0])\n",
    "        peek1 = np.max(y[range1])\n",
    "        rigidity = peek0 / peek1\n",
    "        y = y / rigidity\n",
    "        return y\n",
    "'''\n",
    "#  BPNNet\n",
    "########################################################################################################################\n",
    "#本部分可调\n",
    "learning_rate_max_whole = 0.30\n",
    "learning_rate_min_whole = 0.10\n",
    "epochs_whole = 2000000\n",
    "batch_size_whole = 0\n",
    "threshold = 5e-8\n",
    "########################################################################################################################\n",
    "# active function\n",
    "\n",
    "########################################################################################################################\n",
    "date = '20191212'\n",
    "choose_element = 'Fe2O3' #Na2O  SiO2 Fe2O3 Al2O3 CaO MgO  Na2O TiO2\n",
    "try_num = 3\n",
    "process = 'SmoothedSpectrum' #DenoisedSpectrum SmoothedSpectrum\n",
    "data_file_path = os.path.join(r'D:\\data\\china_2020\\spectra_cut', choose_element)\n",
    "menu_guide_path = r'D:\\data\\Menu_Guide-quantitative.xlsx'\n",
    "save_path_file = os.path.join(r'D:\\data\\china_2020\\result\\BPNN results', date, choose_element+'_4', process)\n",
    "#process_path = ['DenoisedSpectrum', 'SmoothedSpectrum']\n",
    "choose_type = 'Soil_Type'\n",
    "file_list = 'Spectra_Name'\n",
    "sample_list = 'Spectra_Name'\n",
    "data_flag = pd.read_excel(menu_guide_path)\n",
    "file_names = np.array(data_flag[file_list])\n",
    "concentration = np.array(data_flag[choose_element])\n",
    "sample_type = np.array(data_flag[choose_type])\n",
    "sample_name_unique = np.array(data_flag[sample_list])\n",
    "train_test_set = np.array(data_flag['Train']).tolist()\n",
    "type_list = data_flag[choose_type].drop_duplicates(keep='first').tolist()\n",
    "p = 150  #p可调\n",
    "########################################################################################################################\n",
    "# train list\n",
    "#train_position = [i for i, j in enumerate(train_test_set) if j == 1]\n",
    "train_position = [1, 3, 12, 13, 21]\n",
    "# test list\n",
    "#test_position = [i for i, j in enumerate(train_test_set) if j == 0]\n",
    "test_position = [1, 3, 12, 13, 21]\n",
    "########################################################################################################################\n",
    "# Input Data\n",
    "\n",
    "state = 'pellet'\n",
    "pellet_data = np.loadtxt(r'D:\\data\\china_2020\\spectra_cut\\Fe2O3\\pellet_'+process+'.txt')\n",
    "group_tr = None\n",
    "for index_i in train_position:\n",
    "    for j in range(8):\n",
    "        if group_tr is None:\n",
    "            group_tr = index_i\n",
    "        else:\n",
    "            group_tr = np.row_stack((group_tr, index_i))\n",
    "X_tr = np.loadtxt(os.path.join(r'D:\\data\\china_2020\\spectra_cut\\Fe2O3', state+'_'+process+'.txt'))\n",
    "y_tr = np.loadtxt(os.path.join(r'D:\\data\\china_2020\\spectra_cut\\Fe2O3', state+'_'+process+'_y.txt'))\n",
    "y_tr = y_tr.reshape(len(y_tr), 1)\n",
    "state = 'rock'\n",
    "pellet_data = np.loadtxt(r'D:\\data\\china_2020\\spectra_cut\\Fe2O3\\rock_'+process+'.txt')\n",
    "group_te = None\n",
    "for index_i in train_position:\n",
    "    for j in range(8):\n",
    "        if group_te is None:\n",
    "            group_te = index_i\n",
    "        else:\n",
    "            group_te = np.row_stack((group_te, index_i))\n",
    "X_te = np.loadtxt(os.path.join(r'D:\\data\\china_2020\\spectra_cut\\Fe2O3', state+'_'+process+'.txt'))\n",
    "y_te = np.loadtxt(os.path.join(r'D:\\data\\china_2020\\spectra_cut\\Fe2O3', state+'_'+process+'_y.txt'))\n",
    "y_te = y_te.reshape(len(y_te), 1)\n",
    "\n",
    "########################################################################################################################\n",
    "# Te & Tr true concentration\n",
    "group_tr_remove_duplicate = remove_duplicate(group_tr)\n",
    "group_te_remove_duplicate = remove_duplicate(group_te)\n",
    "group_tr_temp = group_tr.reshape(1, -1)\n",
    "group_tr_temp = group_tr_temp[0, :].tolist()\n",
    "group_te_temp = group_te.reshape(1, -1)\n",
    "group_te_temp = group_te_temp[0, :].tolist()\n",
    "order_y_tr = [group_tr_temp.index(x) for x in group_tr_remove_duplicate]\n",
    "order_y_te = [group_te_temp.index(x) for x in group_te_remove_duplicate]\n",
    "y_tr_true = y_tr[order_y_tr]\n",
    "y_te_true = y_te[order_y_te]\n",
    "########################################################################################################################\n",
    "# standard数据归一化\n",
    "'''\n",
    "min_max_scaler1 = preprocessing.MinMaxScaler()\n",
    "X_tr = min_max_scaler1.fit_transform(X_tr)\n",
    "X_te = min_max_scaler1.transform(X_te)\n",
    "min_max_scaler2 = preprocessing.MinMaxScaler()\n",
    "y_tr = min_max_scaler2.fit_transform(y_tr)\n",
    "y_te = min_max_scaler2.transform(y_te)\n",
    "min_max_scaler3 = preprocessing.MinMaxScaler()\n",
    "group_tr_add = min_max_scaler3.fit_transform(group_tr)\n",
    "group_te_add = min_max_scaler3.transform(group_te)\n",
    "'''\n",
    "########################################################################################################################\n",
    "# standard数据归一化for different states\n",
    "min_max_scaler1 = preprocessing.MinMaxScaler()\n",
    "X_tr = min_max_scaler1.fit_transform(X_tr)\n",
    "min_max_scaler1_te = preprocessing.MinMaxScaler()\n",
    "X_te = min_max_scaler1_te.fit_transform(X_te)\n",
    "min_max_scaler2 = preprocessing.MinMaxScaler()\n",
    "y_tr = min_max_scaler2.fit_transform(y_tr)\n",
    "min_max_scaler2_te = preprocessing.MinMaxScaler()\n",
    "y_te = min_max_scaler2_te.fit_transform(y_te)\n",
    "min_max_scaler3 = preprocessing.MinMaxScaler()\n",
    "group_tr_add = min_max_scaler3.fit_transform(group_tr)\n",
    "min_max_scaler3_te = preprocessing.MinMaxScaler()\n",
    "group_te_add = min_max_scaler3_te.fit_transform(group_te)\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "r0, c0 = X_tr.shape\n",
    "print('r0,c0 = '+str(r0)+', '+str(c0))\n",
    "########################################################################################################################\n",
    "\n",
    "k = 6\n",
    "rr = 10\n",
    "\n",
    "predict_train_temp = np.empty(shape=[len(y_tr_true), k * rr])\n",
    "predict_train_temp_rsd = np.empty(shape=[len(y_tr_true), k * rr])\n",
    "predict_val_temp = np.empty(shape=[len(y_tr_true), k * rr])\n",
    "predict_val_temp_rsd = np.empty(shape=[len(y_tr_true), k * rr])\n",
    "predict_tes_temp = np.empty(shape=[len(y_te), k * rr])\n",
    "\n",
    "nn = BPNNet([c0, 5, 1], ['tanh','tanh'], batch_size_whole)   #神经元个数5-8\n",
    "'''''\n",
    "REtes = 0.4\n",
    "R2 = 0.97\n",
    "loop1 = 1oop2 = 1\n",
    "while REtes>0.30  or R2<0.998:\n",
    "    print(\"loop1:\")\n",
    "    print(loop1)\n",
    "'''''\n",
    "rskf = RepeatedStratifiedKFold(n_splits=k, n_repeats=rr)\n",
    "combine = list(rskf.split(X_tr, group_tr))\n",
    "indexi = 0\n",
    "t0 = time()\n",
    "\n",
    "\n",
    "for train_index, val_index in combine:\n",
    "    X_train = X_tr[train_index]\n",
    "    y_train = y_tr[train_index]\n",
    "    group_train = group_tr[train_index]\n",
    "    X_val = X_tr[val_index]\n",
    "    y_val = y_tr[val_index]\n",
    "    group_val = group_tr[val_index]\n",
    "    nn.fit(X_train, y_train, learning_rate_max=learning_rate_max_whole, learning_rate_min=learning_rate_min_whole, epochs=epochs_whole, error_threshold=threshold)\n",
    "    nn.save_weights(save_path_file + r'\\weights' + str(indexi) + '.xlsx')\n",
    "\n",
    "    temp = nn.predict(X_train)\n",
    "    #  inverse transform standard\n",
    "    temp = min_max_scaler2.inverse_transform(temp)\n",
    "    temp1 = remove_duplicate(group_train)\n",
    "    group_train = group_train[:, 0].tolist()\n",
    "    for indexj in range(len(temp1)):\n",
    "        temp_order = [i for i, x in enumerate(group_train) if x == temp1[indexj]]\n",
    "        predict_train_temp[indexj, indexi] = np.mean(temp[temp_order])\n",
    "        predict_train_temp_rsd[indexj, indexi] = np.std(temp[temp_order])\n",
    "        #* np.sqrt(len(temp_order) / (len(temp_order) - 1))\n",
    "\n",
    "    temp = nn.predict(X_val)\n",
    "    #  inverse transform standard\n",
    "    temp = min_max_scaler2.inverse_transform(temp)\n",
    "    temp1 = remove_duplicate(group_val)\n",
    "    group_val = group_val[:, 0].tolist()\n",
    "    for indexj in range(len(temp1)):\n",
    "        temp_order = [i for i, x in enumerate(group_val) if x == temp1[indexj]]\n",
    "        predict_val_temp[indexj, indexi] = np.mean(temp[temp_order])\n",
    "        predict_val_temp_rsd[indexj, indexi] = np.std(temp[temp_order])\n",
    "                                               #* np.sqrt(len(temp_order) / (len(temp_order) - 1))\n",
    "\n",
    "    temp = nn.predict(X_te)\n",
    "    #  inverse transform standard\n",
    "    temp = min_max_scaler2.inverse_transform(temp)\n",
    "    predict_tes_temp[:, indexi] = temp[:, 0]\n",
    "\n",
    "    indexi += 1\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "# 作图使用的calibration val && validation set的predicted value & errorbar\n",
    "#  predicted value\n",
    "predict_train = np.mean(predict_train_temp, axis=1)\n",
    "predict_train_rsd = np.mean(predict_train_temp_rsd, axis=1)\n",
    "predict_val = np.mean(predict_val_temp, axis=1)  # 作图用的calibration线\n",
    "predict_val_rsd = np.mean(predict_val_temp_rsd, axis=1)  # 作图用的calibration线的errorbar\n",
    "# test data set\n",
    "predict_tes = np.mean(predict_tes_temp, axis=1)\n",
    "temp1 = remove_duplicate(group_te)\n",
    "predict_te = np.empty(shape=[len(temp1), 1])  # 作图用的validation线\n",
    "predict_te_rsd = np.empty(shape=[len(temp1), 1])  # 作图用的validation线的errorbar\n",
    "group_te = group_te[:, 0].tolist()\n",
    "for indexj in range(len(temp1)):\n",
    "    temp_order = [i for i, x in enumerate(group_te) if x == temp1[indexj]]\n",
    "    predict_te[indexj, 0] = np.mean(predict_tes[temp_order])\n",
    "    predict_te_rsd[indexj, 0] = np.std(predict_tes[temp_order]) #* np.sqrt(len(temp_order) / (len(temp_order) - 1))\n",
    "# 文章计算Slope 截距\n",
    "print('predict_val = '+str(predict_val))\n",
    "Slope, intercept = optimize.curve_fit(f_1, y_tr_true[:, 0], predict_val)[0]\n",
    "# 文章简图\n",
    "nn0 = 10\n",
    "start = np.min(y_tr_true) - (np.max(y_tr_true) - np.min(y_tr_true)) / 20.0\n",
    "stop = np.max(y_tr_true) + (np.max(y_tr_true) - np.min(y_tr_true)) / 20.0\n",
    "x1 = np.linspace(start, stop, num=nn0, endpoint=True)\n",
    "y1 = Slope * x1 + intercept  ##  拟合曲线\n",
    "plt.plot(x1, y1, color='r', linestyle='--', linewidth=1)\n",
    "plt.errorbar(y_tr_true, predict_val, yerr=predict_val_rsd, fmt='o', marker='o', mfc='white', mec='black', ms=5, mew=1,\n",
    "             ecolor='black', elinewidth=1, capsize=2)\n",
    "plt.errorbar(y_te_true, predict_te[:, 0], yerr=predict_te_rsd[:, 0], fmt='x', marker='x', mfc='white', mec='black',\n",
    "             ms=5, mew=1, ecolor='black', elinewidth=1, capsize=2)\n",
    "plt.legend(['r2', 'val', 'tes'],\n",
    "           loc='upper left',\n",
    "           numpoints=1,\n",
    "           fancybox=True)\n",
    "plt.xlabel('Certified Concentration')\n",
    "plt.ylabel('Predicted Concentration')\n",
    "plt.show()\n",
    "# 文章计算REC RET （使用y_tr_true）REP（使用y_te_true）\n",
    "REC = relative_error(predict_train, y_tr_true)\n",
    "RET = relative_error(predict_val, y_tr_true)\n",
    "REP = relative_error(predict_te, y_te_true)\n",
    "# 文章计算RSD(使用 predict_tes && y_te)\n",
    "RSD = relative_standard_derivation(predict_tes, y_te)\n",
    "# 文章计算LOD\n",
    "LOD = limited_of_detection(Slope, predict_val_rsd)\n",
    "# 文章计算R2（calibration曲线的r2）\n",
    "R2 = r2_score(predict_val, y_tr_true)\n",
    "########################################################################################################################\n",
    "# print the results\n",
    "title = [\"REC\", \"RET\", \"REP\", \"RSD\", \"LOD\", \"R2\"]\n",
    "value = [REC, RET, REP, RSD, LOD, R2]\n",
    "print('title = '+str(title))\n",
    "print('value = '+str(value))\n",
    "########################################################################################################################\n",
    "# save the results\n",
    "# Sheet 1\n",
    "# REC, RET, REP, RSD, LOD, R2 value\n",
    "cmp = [title, value]\n",
    "workbook = xlwt.Workbook(encoding='ascii')\n",
    "worksheet = workbook.add_sheet('Result')\n",
    "for i in range(len(cmp)):\n",
    "    for j, k in enumerate(cmp[i]):\n",
    "        worksheet.write(i, j, k)\n",
    "# Sheet 2\n",
    "worksheet = workbook.add_sheet('Scatter')\n",
    "# calibration scatters value\n",
    "cal_true = ['cal_true']\n",
    "cal_predict = ['cal_predict']\n",
    "cal_stander_derivation = ['cal_stander_derivation']\n",
    "cal_true += y_tr_true[:,0].tolist()\n",
    "print('cal_true = '+str(cal_true))\n",
    "cal_predict += predict_val.tolist()\n",
    "cal_stander_derivation += predict_val_rsd.tolist()\n",
    "cmp0 = [cal_true, cal_predict, cal_stander_derivation]\n",
    "print('cmp0 = '+str(cmp0))\n",
    "for i in range(len(cmp0)):\n",
    "    for j, k in enumerate(cmp0[i]):\n",
    "        worksheet.write(j, i, k)\n",
    "# validation scatters value\n",
    "val_true = ['val_true']\n",
    "val_predict = ['val_predict']\n",
    "val_stander_derivation = ['val_stander_derivation']\n",
    "val_true += y_te_true[:, 0].tolist()\n",
    "val_predict += predict_te[:, 0].tolist()\n",
    "val_stander_derivation += predict_te_rsd[:, 0].tolist()\n",
    "cmp = [val_true, val_predict, val_stander_derivation]\n",
    "print('cmp0 = '+str(cmp0))\n",
    "for i in range(len(cmp)):\n",
    "    for j, k in enumerate(cmp[i]):\n",
    "        worksheet.write(j, i+len(cmp0), k)\n",
    "# Sheet 3\n",
    "worksheet = workbook.add_sheet('fitting')\n",
    "# fitting line value\n",
    "fitting_x = [\"fitting_x\"]\n",
    "fitting_y = [\"fitting_y\"]\n",
    "fitting_x += x1.tolist()\n",
    "fitting_y += y1.tolist()\n",
    "cmp = [fitting_x, fitting_y]\n",
    "for i in range(len(cmp)):\n",
    "    for j, k in enumerate(cmp[i]):\n",
    "        worksheet.write(j, i, k)\n",
    "workbook.save(os.path.join(save_path_file, r'result.xlsx'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 8, 16, 24, 32]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_y_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
